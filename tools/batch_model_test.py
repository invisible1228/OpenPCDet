#!/usr/bin/env python3
import os
import subprocess
import argparse
import json
import pandas as pd
from datetime import datetime

class ModelTester:
    def __init__(self):
        self.results = {}
        
    def test_single_model(self, cfg_file, ckpt_path, model_name, test_set='val'):
        """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
        
        print(f"ğŸš€ å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_name}")
        print(f"   é…ç½®æ–‡ä»¶: {cfg_file}")
        print(f"   æ¨¡å‹æƒé‡: {ckpt_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(ckpt_path):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ckpt_path}")
            return None
            
        # æ„å»ºæµ‹è¯•å‘½ä»¤
        cmd = [
            'python', 'tools/test.py',
            '--cfg_file', cfg_file,
            '--ckpt', ckpt_path,
            '--batch_size', '1',
            '--workers', '4',
            '--extra_tag', f'{model_name}_test',
            '--eval_all',
            '--save_to_file'
        ]
        
        print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        try:
            # è¿è¡Œæµ‹è¯•
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)
            
            if result.returncode == 0:
                print(f"âœ… {model_name} æµ‹è¯•æˆåŠŸ")
                
                # è§£æç»“æœ
                output = result.stdout
                metrics = self.parse_test_output(output)
                
                # ä¿å­˜è¯¦ç»†è¾“å‡º
                with open(f'test_output_{model_name}.txt', 'w') as f:
                    f.write(output)
                
                return metrics
            else:
                print(f"âŒ {model_name} æµ‹è¯•å¤±è´¥")
                print(f"é”™è¯¯ä¿¡æ¯: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            print(f"â° {model_name} æµ‹è¯•è¶…æ—¶")
            return None
        except Exception as e:
            print(f"âŒ {model_name} æµ‹è¯•å¼‚å¸¸: {e}")
            return None
    
    def parse_test_output(self, output):
        """è§£ææµ‹è¯•è¾“å‡ºï¼Œæå–å…³é”®æŒ‡æ ‡"""
        import re
        
        metrics = {}
        
        # KITTIè¯„ä¼°ç»“æœæ¨¡å¼
        patterns = {
            'car_easy_3d': r'Car AP@0\.70, 0\.70, 0\.70:\s*bbox AP:([\d\.]+), ([\d\.]+), ([\d\.]+)\s*bev AP:([\d\.]+), ([\d\.]+), ([\d\.]+)\s*3d AP:([\d\.]+), ([\d\.]+), ([\d\.]+)',
            'pedestrian_3d': r'Pedestrian AP@0\.50, 0\.50, 0\.50:\s*bbox AP:([\d\.]+), ([\d\.]+), ([\d\.]+)\s*bev AP:([\d\.]+), ([\d\.]+), ([\d\.]+)\s*3d AP:([\d\.]+), ([\d\.]+), ([\d\.]+)',
            'cyclist_3d': r'Cyclist AP@0\.50, 0\.50, 0\.50:\s*bbox AP:([\d\.]+), ([\d\.]+), ([\d\.]+)\s*bev AP:([\d\.]+), ([\d\.]+), ([\d\.]+)\s*3d AP:([\d\.]+), ([\d\.]+), ([\d\.]+)'
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, output)
            if match:
                class_name = key.split('_')[0]
                # æå–3D APçš„ä¸‰ä¸ªéš¾åº¦å€¼
                metrics[f'{class_name}_3d_easy'] = float(match.group(7))
                metrics[f'{class_name}_3d_moderate'] = float(match.group(8))
                metrics[f'{class_name}_3d_hard'] = float(match.group(9))
                
                # æå–BEV AP
                metrics[f'{class_name}_bev_easy'] = float(match.group(4))
                metrics[f'{class_name}_bev_moderate'] = float(match.group(5))
                metrics[f'{class_name}_bev_hard'] = float(match.group(6))
                
                # æå–2D AP
                metrics[f'{class_name}_2d_easy'] = float(match.group(1))
                metrics[f'{class_name}_2d_moderate'] = float(match.group(2))
                metrics[f'{class_name}_2d_hard'] = float(match.group(3))
        
        # æŸ¥æ‰¾æ€»ä½“æŒ‡æ ‡
        overall_pattern = r'Average.*AP.*:([\d\.]+)'
        overall_match = re.search(overall_pattern, output)
        if overall_match:
            metrics['overall_ap'] = float(overall_match.group(1))
        
        return metrics
    
    def test_multiple_models(self, model_configs):
        """æµ‹è¯•å¤šä¸ªæ¨¡å‹"""
        
        print(f"ğŸ“Š å¼€å§‹æ‰¹é‡æµ‹è¯• {len(model_configs)} ä¸ªæ¨¡å‹")
        
        for model_name, config in model_configs.items():
            print(f"\n{'='*50}")
            print(f"æµ‹è¯•æ¨¡å‹: {model_name}")
            print(f"{'='*50}")
            
            metrics = self.test_single_model(
                config['cfg_file'],
                config['ckpt_path'],
                model_name
            )
            
            if metrics:
                self.results[model_name] = {
                    'metrics': metrics,
                    'config': config,
                    'timestamp': datetime.now().isoformat()
                }
                
                # æ‰“å°å…³é”®æŒ‡æ ‡
                print(f"ğŸ“ˆ {model_name} å…³é”®æŒ‡æ ‡:")
                if 'car_3d_moderate' in metrics:
                    print(f"   Car 3D (Moderate): {metrics['car_3d_moderate']:.4f}")
                if 'pedestrian_3d_moderate' in metrics:
                    print(f"   Pedestrian 3D (Moderate): {metrics['pedestrian_3d_moderate']:.4f}")
                if 'cyclist_3d_moderate' in metrics:
                    print(f"   Cyclist 3D (Moderate): {metrics['cyclist_3d_moderate']:.4f}")
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self.generate_comparison_report()
    
    def generate_comparison_report(self):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        if not self.results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯ç”¨äºç”ŸæˆæŠ¥å‘Š")
            return
        
        print(f"\nğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
        
        # åˆ›å»ºDataFrame
        df_data = []
        for model_name, result in self.results.items():
            row = {'Model': model_name}
            row.update(result['metrics'])
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        
        # ä¿å­˜ä¸ºCSV
        df.to_csv('model_comparison_results.csv', index=False)
        print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: model_comparison_results.csv")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report(df)
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.generate_plots(df)
    
    def generate_markdown_report(self, df):
        """ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š"""
        
        with open('model_test_report.md', 'w') as f:
            f.write("# æ¨¡å‹æµ‹è¯•å¯¹æ¯”æŠ¥å‘Š\n\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æµ‹è¯•é…ç½®\n\n")
            f.write("| æ¨¡å‹ | é…ç½®æ–‡ä»¶ | æƒé‡æ–‡ä»¶ |\n")
            f.write("|------|----------|----------|\n")
            
            for model_name, result in self.results.items():
                cfg_file = os.path.basename(result['config']['cfg_file'])
                ckpt_file = os.path.basename(result['config']['ckpt_path'])
                f.write(f"| {model_name} | {cfg_file} | {ckpt_file} |\n")
            
            f.write("\n## 3Dæ£€æµ‹ç»“æœ (Moderateéš¾åº¦)\n\n")
            f.write("| æ¨¡å‹ | Car | Pedestrian | Cyclist |\n")
            f.write("|------|-----|------------|--------|\n")
            
            for _, row in df.iterrows():
                model = row['Model']
                car_3d = row.get('car_3d_moderate', 0)
                ped_3d = row.get('pedestrian_3d_moderate', 0)
                cyc_3d = row.get('cyclist_3d_moderate', 0)
                f.write(f"| {model} | {car_3d:.4f} | {ped_3d:.4f} | {cyc_3d:.4f} |\n")
            
            f.write("\n## BEVæ£€æµ‹ç»“æœ (Moderateéš¾åº¦)\n\n")
            f.write("| æ¨¡å‹ | Car | Pedestrian | Cyclist |\n")
            f.write("|------|-----|------------|--------|\n")
            
            for _, row in df.iterrows():
                model = row['Model']
                car_bev = row.get('car_bev_moderate', 0)
                ped_bev = row.get('pedestrian_bev_moderate', 0)
                cyc_bev = row.get('cyclist_bev_moderate', 0)
                f.write(f"| {model} | {car_bev:.4f} | {ped_bev:.4f} | {cyc_bev:.4f} |\n")
            
            # æ·»åŠ æ”¹è¿›åˆ†æ
            if len(df) > 1:
                f.write("\n## æ”¹è¿›åˆ†æ\n\n")
                baseline_idx = 0  # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯åŸºå‡†
                baseline_name = df.iloc[baseline_idx]['Model']
                
                for i in range(1, len(df)):
                    model_name = df.iloc[i]['Model']
                    f.write(f"### {model_name} vs {baseline_name}\n\n")
                    
                    for metric in ['car_3d_moderate', 'pedestrian_3d_moderate', 'cyclist_3d_moderate']:
                        if metric in df.columns:
                            baseline_val = df.iloc[baseline_idx][metric]
                            current_val = df.iloc[i][metric]
                            improvement = current_val - baseline_val
                            percentage = (improvement / baseline_val * 100) if baseline_val > 0 else 0
                            
                            class_name = metric.split('_')[0].title()
                            f.write(f"- {class_name} 3D: {improvement:+.4f} ({percentage:+.2f}%)\n")
                    f.write("\n")
        
        print(f"âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: model_test_report.md")
    
    def generate_plots(self, df):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        import matplotlib.pyplot as plt
        import numpy as np
        
        # 3Dæ£€æµ‹ç»“æœå¯¹æ¯”
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=16)
        
        # 3D APå¯¹æ¯”
        metrics_3d = ['car_3d_moderate', 'pedestrian_3d_moderate', 'cyclist_3d_moderate']
        labels = ['Car', 'Pedestrian', 'Cyclist']
        
        if all(metric in df.columns for metric in metrics_3d):
            ax1 = axes[0, 0]
            x = np.arange(len(labels))
            width = 0.8 / len(df)
            
            for i, (_, row) in enumerate(df.iterrows()):
                values = [row[metric] for metric in metrics_3d]
                ax1.bar(x + i * width, values, width, label=row['Model'])
            
            ax1.set_xlabel('ç±»åˆ«')
            ax1.set_ylabel('3D AP')
            ax1.set_title('3Dæ£€æµ‹APå¯¹æ¯” (Moderate)')
            ax1.set_xticks(x + width * (len(df) - 1) / 2)
            ax1.set_xticklabels(labels)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
        
        # BEV APå¯¹æ¯”
        metrics_bev = ['car_bev_moderate', 'pedestrian_bev_moderate', 'cyclist_bev_moderate']
        
        if all(metric in df.columns for metric in metrics_bev):
            ax2 = axes[0, 1]
            
            for i, (_, row) in enumerate(df.iterrows()):
                values = [row[metric] for metric in metrics_bev]
                ax2.bar(x + i * width, values, width, label=row['Model'])
            
            ax2.set_xlabel('ç±»åˆ«')
            ax2.set_ylabel('BEV AP')
            ax2.set_title('BEVæ£€æµ‹APå¯¹æ¯” (Moderate)')
            ax2.set_xticks(x + width * (len(df) - 1) / 2)
            ax2.set_xticklabels(labels)
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        
        # éš¾åº¦å¯¹æ¯” (ä»¥Carä¸ºä¾‹)
        if all(f'car_3d_{diff}' in df.columns for diff in ['easy', 'moderate', 'hard']):
            ax3 = axes[1, 0]
            difficulties = ['Easy', 'Moderate', 'Hard']
            x_diff = np.arange(len(difficulties))
            
            for i, (_, row) in enumerate(df.iterrows()):
                values = [row[f'car_3d_{diff}'] for diff in ['easy', 'moderate', 'hard']]
                ax3.bar(x_diff + i * width, values, width, label=row['Model'])
            
            ax3.set_xlabel('éš¾åº¦')
            ax3.set_ylabel('3D AP')
            ax3.set_title('Car 3Dæ£€æµ‹ä¸åŒéš¾åº¦å¯¹æ¯”')
            ax3.set_xticks(x_diff + width * (len(df) - 1) / 2)
            ax3.set_xticklabels(difficulties)
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
        if len(df) <= 3:  # åªåœ¨æ¨¡å‹æ•°é‡ä¸å¤šæ—¶ç»˜åˆ¶é›·è¾¾å›¾
            ax4 = axes[1, 1]
            self.plot_radar_chart(df, ax4)
        
        plt.tight_layout()
        plt.savefig('model_comparison_plots.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: model_comparison_plots.png")
    
    def plot_radar_chart(self, df, ax):
        """ç»˜åˆ¶é›·è¾¾å›¾"""
        import numpy as np
        
        metrics = ['car_3d_moderate', 'pedestrian_3d_moderate', 'cyclist_3d_moderate',
                   'car_bev_moderate', 'pedestrian_bev_moderate', 'cyclist_bev_moderate']
        
        available_metrics = [m for m in metrics if m in df.columns]
        
        if len(available_metrics) < 3:
            ax.text(0.5, 0.5, 'Not enough metrics\nfor radar chart', 
                    ha='center', va='center', transform=ax.transAxes)
            return
        
        # è®¡ç®—è§’åº¦
        angles = np.linspace(0, 2 * np.pi, len(available_metrics), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆ
        
        ax.set_theta_offset(np.pi / 2)
        ax.set_theta_direction(-1)
        
        # ç»˜åˆ¶æ¯ä¸ªæ¨¡å‹
        for _, row in df.iterrows():
            values = [row[metric] for metric in available_metrics]
            values += values[:1]  # é—­åˆ
            
            ax.plot(angles, values, 'o-', linewidth=2, label=row['Model'])
            ax.fill(angles, values, alpha=0.25)
        
        # è®¾ç½®æ ‡ç­¾
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels([m.replace('_', '\n') for m in available_metrics])
        ax.legend()
        ax.set_title('ç»¼åˆæ€§èƒ½é›·è¾¾å›¾')

def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡æµ‹è¯•æ¨¡å‹ç²¾åº¦')
    parser.add_argument('--models_config', type=str, default=None, help='æ¨¡å‹é…ç½®JSONæ–‡ä»¶')
    args = parser.parse_args()
    
    tester = ModelTester()
    
    # é»˜è®¤æµ‹è¯•é…ç½®
    default_models = {
        'baseline_pointpillar': {
            'cfg_file': 'tools/cfgs/kitti_models/pointpillar.yaml',
            'ckpt_path': 'output/kitti_models/pointpillar/baseline_pointpillar/ckpt/checkpoint_epoch_80.pth'
        },
        'pillarfocus_full': {
            'cfg_file': 'tools/cfgs/custom_models/pillarfocus_pop_rcnn.yaml',
            'ckpt_path': 'output/custom_models/pillarfocus_pop_rcnn/pillarfocus_full/ckpt/checkpoint_epoch_80.pth'
        }
    }
    
    if args.models_config and os.path.exists(args.models_config):
        with open(args.models_config, 'r') as f:
            models_config = json.load(f)
    else:
        models_config = default_models
    
    # æ‰§è¡Œæ‰¹é‡æµ‹è¯•
    tester.test_multiple_models(models_config)

if __name__ == "__main__":
    main()